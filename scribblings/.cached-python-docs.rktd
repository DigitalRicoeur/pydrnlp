#hash(((pydrnlp stop_words) . ("module" #hasheq((classes . ()) (functions . (("function" #hasheq((name . "revision") (signature . ("signature" #hasheq((parameters . ()) (return . #f)))) (text . ("docstring" "Identifies the revision of `pydrnlp.tokenizer.stop_words`.")))) ("function" #hasheq((name . "tokenAnyIsStopForLanguage") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "token"))) ("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "nlp"))))) (return . #f)))) (text . ("docstring" "Returns `True` if any form of `token` is a stop word\nfor the `spacy.language.Language` instance `nlp`.\n\nThis is needed because `spacy.tokens.Token.is_stop`\nreturns `False` when the token itself is not a stop word,\neven if a more normalized form might be.\n\nSince spaCy v2.1.0, `spacy.tokens.Token.is_stop`\nshould be properly case-insensitive, so the primary job of this\nfunction is now to also check `token.lemma_ in nlp.Defaults.stop_words`.\nComments on an old version of this function claim that test will\nsometimes pass even when `token.is_stop is False`,\nthough we should collect examples of when/why, because I've forgotten ...\n\nAs a temporary measure while upgrading spaCy v2.0.0 to v2.1.0,\nthis function currently also does the case-insensitivity\nchecks that should no longer be needed,\nso that we can confirm that they are never necessary.\n\nTODO: if this function is as trivial as it seems given spaCy v2.1.0,\nunless some other tool is likely to reuse this logic,\nit might be better to inline this into `pydrnlp.trends`.")))))) (text . ("docstring" "Utilities for working with spaCy \"stop words.\""))))) ((pydrnlp) . ("module" #hasheq((classes . ()) (functions . ()) (text . #f)))) ((pydrnlp jsonio) . ("module" #hasheq((classes . ()) (functions . (("function" #hasheq((name . "map_json_lines") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "proc"))))) (return . #f)))) (text . ("docstring" "Runs a newline-delimited JSON IO loop,\nusing proc to transform the parsed values.")))) ("function" #hasheq((name . "write_json_line") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "jsOut"))))) (return . #f)))) (text . ("docstring" "Writes the JSON form of jsOut, followed by a newline,\nthen flushes the output.\n\nIf fOut is False, and by default, output will be written to sys.stdout.")))))) (text . ("docstring" "Provides JSON IO functions.\n\nThis module imposes the invariant that JSON values must be\ndelimited by newlines (i.e. \"\\n\") and that the JSON values\nin input may not use the newline character internally,\neven where insignificant whitespace is allowed by the JSON spec.\nUsing newlines as a delimiter avoids a limitation of Python's\njson.load(), which blocks until it encounters an EOF.\nThis module also writes JSON with a terminating newline,\nthough Racket's JSON parser doesn't need this."))))) ((pydrnlp language) . ("module" #hasheq((classes . ()) (functions . (("function" #hasheq((name . "get") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "langStr"))))) (return . #f)))) (text . ("docstring" "Returns a `spacy.language.Language` instance for the given IANA string.\n\nModels from SpaCy are loaded lazily.")))) ("function" #hasheq((name . "revision") (signature . ("signature" #hasheq((parameters . ()) (return . #f)))) (text . #f))))) (text . ("docstring" "Uniform, lazy loading of SpaCy language models\n\nThe primary entry point for Spacy functionality\nis through a `spacy.language.Language` object,\nwhich must be loaded through a language-specific\nmodel package.\nLoading a language is expensive and should not be repeated.\nAdditionally, pydrnlp should be change which model we\nuse for each supported language without necessitating changes\nin every Python module that needs to use `spacy.language.Language` objects.\n\nThe functionality is supported through `pydrnlp.language.get()`,\nwhich is similar in spirit to `spacy.load()`.\n\n**TODO:** en_core_web_lg sounds like it has pre-trained models and may give\nbetter accuracy. OTOH it is an order of magnitude bigger (667 vs 36 MB)."))))) ((pydrnlp doc) . ("module" #hasheq((classes . ()) (functions . (("function" #hasheq((name . "docClass") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "name"))) ("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "value"))))) (return . #f)))) (text . ("docstring" "Documents the class `value` as `name`.\n\nThe resulting object is tagged `\"class\"` and has\nthe following keys:\n\n- `\"name\"`: `name`.\n\n- `\"text\"`: the result of `getDocText(value)`.\n\n- `\"bases\"`: a list of base classes, where each item is tagged `\"base\"`\n  and has fields `\"name\"` and `\"module\"`, both of which are mapped to\n  strings.\n\n- `\"methods\"`: a list of function documentation objects\n  (see `docFunction`) for the class's public methods, including `__init__`.")))) ("function" #hasheq((name . "docFunction") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "name"))) ("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "value"))))) (return . #f)))) (text . ("docstring" "Documents the function `value` as `name`.\n\nThe resulting object is tagged `\"function\"`.\nIt has the following keys:\n\n- `\"name\"`: `name`.\n\n- `\"text\"`: the result of `getDocText(value)`.\n\n- `\"signature\"`: the result of `docSignature(value)`.")))) ("function" #hasheq((name . "docModpath") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "modpath"))))) (return . #f)))) (text . ("docstring" "Extracts documentation from the module at the given modpath.\n\nThe resulting object is tagged `\"modpath\"`.\nThe value of its `\"modpath\"` key is always the given modpath.\nThe value of its `\"module\"` key will usually be the\nsame kind of value produced by `docModule`, but it might be\n`False`, meaning that the module was not found, or\n`\"ErrorDuringImport\"`, meaning that the module was found,\nbut an exception occured while trying to run it to\nobtain a module object.")))) ("function" #hasheq((name . "docModule") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "mod"))))) (return . #f)))) (text . ("docstring" "Extracts the documentation for a given module object.\n\nThe resulting object is tagged `\"module\"`.\nIt has the following keys:\n\n- `\"text\"`: the result of `getDocText(mod)`.\n\n- `\"functions\"`: a list of results from `docFunction`.")))) ("function" #hasheq((name . "docSignature") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "proc"))))) (return . #f)))) (text . ("docstring" "Tries to extract documentation about the signature\nof the given object.\n\nThe result may be `\"TypeError\"` if the given object\ndoes not support signatures or `\"ValueError\"` if it does,\nbut no signature could be found.\nOtherwise, it will be an object tagged `\"signature\"`\nwith the following fields:\n\n- `\"parameters\"`: a list of objects tagged `\"parameter\"` (see below).\n\n- `\"return\"`: either a string representing the function's return\n  annotation or `False` if the function had none.\n\nA parameter object has the following fields:\n\n- `\"name\"`: a string naming the formal argument.\n\n- `\"kind\"`: one of `\"POSITIONAL_ONLY\"`, `\"POSITIONAL_OR_KEYWORD\"`,\n  `\"VAR_POSITIONAL\"`, `\"KEYWORD_ONLY\"`, or `\"VAR_KEYWORD\"`.\n\n- `\"annotation\"`: a string representing the argument's annotation,\n  or `False` if it has none.\n\n- `\"default\"`: a string representing the argument's default value,\n  or `False` if it has none.")))) ("function" #hasheq((name . "getDocText") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "obj"))))) (return . #f)))) (text . ("docstring" "Attempts to get some text documenting obj.\n\nThe result is based on what was obtained:\n\n- If there was a docstring, it is tagged `\"docstring\"`.\n\n- If comments were found, they are tagged `\"comments\"`.\n\n- If both of those are missing or empty, returns `False`.")))))) (text . ("docstring" "Tools for extracting Python documentation to structured JSON.\n\nThis module is developed with pydrnlp, but it isn't really\nspecific to pydrnlp or Digital Digital Ric≈ìur.\nIf it stabalizes, it should be distributed separately.\n\nWhile this module exports certain public functions,\nit is primarily intended for programatic use with `__name__==\"__main__\"`.\n\nAll non-trivial JSON values produced by this module are\ndesigned as type-tagged objects: that is, each is a two-element\narray, with the first element being a string identifying the type\nof the value and the second element being a JSON object\ncontaining the value's payload."))))) ((pydrnlp trends) . ("module" #hasheq((classes . ()) (functions . (("function" #hasheq((name . "analyze_all") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "jsIn"))))) (return . #f)))) (text . ("docstring" "Tokenizes JsIn. **TODO: document this.**")))) ("function" #hasheq((name . "revision") (signature . ("signature" #hasheq((parameters . ()) (return . #f)))) (text . ("docstring" "Returns a non-False JSON value identifying the current revision.\n\nThe intended purpose is for clients to\nbe able to cache responses:\nAs long as tokenizerRevision() returns the same value,\ncalling this API on the same input should return equivalent output.\nThis enables clients to cache responses.\nThe returned value incorporates the results of\npydrnlp.drtoken.tokenFilterRevision() and\npydrnlp.drlanguage.drLanguageRevision().\n\nWhen the result of tokenizerRevision() changes, any cache is stale.")))) ("function" #hasheq((name . "tokenShouldUseForLang") (signature . ("signature" #hasheq((parameters . (("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "token"))) ("parameter" #hasheq((annotation . #f) (default . #f) (kind . "POSITIONAL_OR_KEYWORD") (name . "lang"))))) (return . #f)))) (text . ("docstring" "Recognizes tokens which should be included in counting\nwith respect to the given `spacy.language.Language` instance.\n\nSome kinds of tokens which should be excluded:\n\n- punctuation;\n- whitespace;\n- stop words (see `pydrnlp.tokenAnyIsStopForLanguage`); and\n- tokens which have a \"boring\" part-of-speech tag.\n\nPart-of-speech tags that are considered \"boring\"\nnotably include `\"NUM\"` (numeral) and `\"SYM\"` (symbol).")))))) (text . ("docstring" "Core engine for the \"Trends\" tool.\n\nTypes used in this module:\n--------------------------\n\n- `JsToken`:\n    `{\"lemma\": str, \"text\": str}`\n\n- `JsOutSegment`:\n    `{\"key\": JsExpr, \"tokenized\": Listof[JsToken]}`\n\n- `JsOut`:\n    `Listof[JsOutSegment]`\n\n\n- `JsInSegment`:\n    `{\"key\": JsExpr, \"body\": str}`\n\n- `JsIn`:\n    `{LangStr: Listof[JsInSegment]}`\n\nWould it be useful for JsToken to track the token's\n\n  a) start and end positions and/or\n\n  b) index among significant tokens in the document?\n\nMaybe preserving the ordering within the segment is good enough."))))))